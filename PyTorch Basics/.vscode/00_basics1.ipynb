{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da42d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Installing PyTorch and checking the version we are using that\n",
    "import torch #the purpose of this is to make the torch library available to use for the rest of the code\n",
    "torch.__version__ #the two long dashes __word__ are called dunder or magic methods which are special methods in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840b3bd",
   "metadata": {},
   "source": [
    "# Introduction to Tensors\n",
    "\n",
    "- Fundamental building block of ML\n",
    "- Represent data in a numerical way\n",
    "- Could represent an image a tensor shape [3, 224, 224], which would mean [color_channels, height, width]\n",
    "    - 3 color channels rgb\n",
    "    - Height = 224 pixels\n",
    "    - Width = 224 pixels\n",
    "    - This tensor would have 3 dimensions\n",
    "- *Read through the torch.Tensor class documentation page!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9443cb",
   "metadata": {},
   "source": [
    "## Scalar Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8392f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "The number of dimensions of the scalar is: 0 dimensions\n",
      "Turning the torch Tensor into a Python int variable: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "torch.__version__\n",
    "#First thing we do is create a scalar \n",
    "#A Scalar is a single number and is a 0-dimensional tensor that \n",
    "\n",
    "scalar = torch.tensor(7) \n",
    "scalar #although its just the number 7, it is the type of torch.Tensor\n",
    "print(scalar) #this gives tensor(7)\n",
    "\n",
    "#Check dimensions of the tensor using ndim\n",
    "scalar.ndim \n",
    "print(f\"The number of dimensions of the scalar is: {scalar.ndim} dimensions\")\n",
    "\n",
    "#If we want to retrieve the number from the tensor, turn it from type torch.Tensor into a Python int variable \n",
    "#Use the item method\n",
    "number=scalar.item()\n",
    "print(f\"Turning the torch Tensor into a Python int variable: {number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a85321",
   "metadata": {},
   "source": [
    "## Vector Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d8d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 7.])\n",
      "The dimensions of the vector is: 1\n",
      "The shape of the vector is: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Vectors \n",
    "# are a single dimensional tensor but can contain many numbers\n",
    "# Could have [3, 2] to describe [bedrooms, bathrooms] in your house\n",
    "# You could have [3,2,2] to describe bedrooms bathroom and cars parked\n",
    "# Vectors are flexible in what they can represent\n",
    "\n",
    "#Vector\n",
    "vector = torch.Tensor([7,7]) #Notice one bracket on each side\n",
    "print(vector) #Notice that this print statement will include the word tensor\n",
    "\n",
    "#Checking the dimensions of the vector\n",
    "vector.ndim #There are no () after ndim becauser it is not a method, it is an attribute\n",
    "print(f\"The dimensions of the vector is: {vector.ndim}\") \n",
    "\n",
    "#The dimension returned here is 1, because it is a 1D tensor\n",
    "#It is easy to know what the dimension is by looking at the number of brackets on ONE SIDE\n",
    "\n",
    "#Shape of Vector (how many elements are in the vector)\n",
    "vector.shape\n",
    "print(f\"The shape of the vector is: {vector.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7ea0d",
   "metadata": {},
   "source": [
    "## Matrix Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bcbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Created: tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "The number of dimensions (brackets) of the matrix is: 2\n",
      "The shape of this matrix (rows, cols) is: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "#Matrix\n",
    "#Since this is a 2D tensor, and we are making it a 2x2 shape will return size, make sure you separate the rows with a comma\n",
    "MATRIX = torch.tensor( [ [7, 8],\n",
    "                        [9, 10]])\n",
    "print(f\"Matrix Created: {MATRIX}\")\n",
    "\n",
    "#Checking the number of dimensions, should be 2\n",
    "print(f\"The number of dimensions (brackets) of the matrix is: {MATRIX.ndim}\")\n",
    "\n",
    "#When we test the shape of a matrix, instead of number of elements (like vectors), we get number of rows and columns\n",
    "print(f\"The shape of this matrix (rows, cols) is: {MATRIX.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bac3a0",
   "metadata": {},
   "source": [
    "## N-Dimensional Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb4b7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor created is: tensor([[[1, 2, 3],\n",
      "         [3, 6, 9],\n",
      "         [2, 4, 5]]])\n",
      "The above tensor has (number of brackets) 3 dimensions\n",
      "The tensor has a shape of: torch.Size([1, 3, 3])\n",
      "The new tensor is: tensor([[[1, 1],\n",
      "         [1, 1],\n",
      "         [1, 1]]])\n",
      "The shape of the new tensor is: torch.Size([1, 3, 2]) which can be though of as 1 3x2 matrix\n"
     ]
    }
   ],
   "source": [
    "#Tensor\n",
    "#Generally, Tensors are 3D or more\n",
    "#Reminder: 0D = Scalar, 1D = Vector, 2D = Matrix\n",
    "\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "\n",
    "print(f\"The tensor created is: {TENSOR}\")\n",
    "\n",
    "#Tensors can represent almost anything, for example the one we just created could be in an excel sheet:\n",
    "#Days of week:      1 2 3\n",
    "#Steak Sales:       3 6 9\n",
    "#Almond Milk Sales: 2 4 5\n",
    "\n",
    "#What will be the number of dimensions (remember, number of square brackets)\n",
    "print(f\"The above tensor has (number of brackets) {TENSOR.ndim} dimensions\")\n",
    "\n",
    "#What will the shape be? Remember, the numbers shown in shape represent # elements in outer to inner (0->nth) dimensions\n",
    "# This tensor has 1 element in outer dimension (a 3x3 matrix)\n",
    "# 3 elements in the middle dimension (3 vectors which are the rows)\n",
    "# 3 elements in the inner dimension (3 numbers in each vector which are the columns)\n",
    "print(f\"The tensor has a shape of: {TENSOR.shape}\")\n",
    "\n",
    "new_tensor = torch.tensor([[[1,1],\n",
    "                            [1,1],\n",
    "                            [1,1]]])\n",
    "print(f\"The new tensor is: {new_tensor}\")\n",
    "print(f\"The shape of the new tensor is: {new_tensor.shape} which can be though of as 1 3x2 matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52cc32a",
   "metadata": {},
   "source": [
    "## Summary of Tensors\n",
    "\n",
    "Scalar: torch.tensor(1)\n",
    "- Single number\n",
    "- ndim=0\n",
    "- scalar.shape returns torch.Size([])\n",
    "- use scalar.item() to get it from tensor to python var\n",
    "- v\n",
    "\n",
    "Vector: torch.tensor([1,1])\n",
    "- Multiple numbers, has direction\n",
    "- ndim-1\n",
    "- vector.shape returns torch.Size([# of items])\n",
    "- y\n",
    "\n",
    "Matrix: torch.tensor([[1,1],[1,1]])\n",
    "- 2 Dimensional array of numbers of nxm\n",
    "- ndim=2\n",
    "- matrix.shape return torch.Size([#rows, #columns])\n",
    "\n",
    "Tensor: torch.tensor([[[1,1],[1,1],[1,1]]])\n",
    "- n dimensional array of numbers (think matrices with matrices inside)\n",
    "- ndim=3 (number of brackets!)\n",
    "- tensor.shape here gives torch.Size([1,3,2])m can think of this as 1 3x2 matrix\n",
    "    - it has dim of 3 because there is specifically 1 matrix, there could be 2 or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98619f40",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor Initialization\n",
    "It is very rare to actually create tensors by hand as we did above\n",
    "\n",
    "## Random Tensors\n",
    "ML models start out with **large random tensors** of numbers and *adjusts* these random numbers as it works through data to better represent it\n",
    "\n",
    "You define how model starts (*initialization*), looks at data (*representation*), and updates (*optimization*) random numbers\n",
    "\n",
    "Let us create some random tensors now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82bd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random tensor initialized with torch.rand(3,4) is:\n",
      " tensor([[0.5680, 0.3554, 0.2648, 0.6336],\n",
      "        [0.9397, 0.6918, 0.6551, 0.3318],\n",
      "        [0.6601, 0.4567, 0.3523, 0.6074]]) \n",
      "with a datatype of: torch.float32\n",
      "THe tensor has a shape of: torch.Size([3, 4]) and a dimension of: 2\n",
      "The bigger random tensor is: tensor([[[[0.6002, 0.5602],\n",
      "          [0.3055, 0.7475],\n",
      "          [0.9063, 0.3638],\n",
      "          [0.8091, 0.9995]],\n",
      "\n",
      "         [[0.1936, 0.1750],\n",
      "          [0.4837, 0.5747],\n",
      "          [0.4713, 0.1408],\n",
      "          [0.0995, 0.5007]],\n",
      "\n",
      "         [[0.7947, 0.5934],\n",
      "          [0.2074, 0.5156],\n",
      "          [0.8116, 0.5935],\n",
      "          [0.3213, 0.3380]]],\n",
      "\n",
      "\n",
      "        [[[0.4625, 0.8709],\n",
      "          [0.2010, 0.2471],\n",
      "          [0.0499, 0.6338],\n",
      "          [0.0359, 0.3935]],\n",
      "\n",
      "         [[0.3626, 0.8129],\n",
      "          [0.3562, 0.3625],\n",
      "          [0.5605, 0.1850],\n",
      "          [0.6653, 0.0507]],\n",
      "\n",
      "         [[0.1822, 0.4924],\n",
      "          [0.6575, 0.6219],\n",
      "          [0.4614, 0.3515],\n",
      "          [0.5467, 0.2246]]]]) \n",
      "with a shape of: torch.Size([2, 3, 4, 2]) and a dimension of: 4\n"
     ]
    }
   ],
   "source": [
    "#Creating random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "print(f\"The random tensor initialized with torch.rand(3,4) is:\\n {random_tensor} \\nwith a datatype of: {random_tensor.dtype}\") \n",
    "#Notice that the numbers are between 0 and 1 because we used torch.rand() which is a random number between 0 and 1\n",
    "\n",
    "print(f\"THe tensor has a shape of: {random_tensor.shape} and a dimension of: {random_tensor.ndim}\") #ndim=2 because it's a matrix, so here trick is count number of arguments\n",
    "\n",
    "#The flexibility of torch.rand() is that we can adjust the size to be whatever we want\n",
    "#Remember that this rand function takes in the SHAPE of the tensor\n",
    "\n",
    "bigger_random_tensor = torch.rand(2,3,4,2) #Imagine this as a pair of: (3 sets of (4x2 matrices)), which gives ndim of 4 (# of arguments) and shape of 2,3,4,2\n",
    "print(f\"The bigger random tensor is: {bigger_random_tensor} \\nwith a shape of: {bigger_random_tensor.shape} and a dimension of: {bigger_random_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea91cc1",
   "metadata": {},
   "source": [
    "### Random Tensor to represent an RGB 224x224 Image\n",
    "Suppose we want a random tensor in the common image shape of 224x224x3 (height, width, color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Image Tensor is: tensor([[[0.4889, 0.2771, 0.2280],\n",
      "         [0.8962, 0.6210, 0.5955],\n",
      "         [0.0240, 0.0587, 0.3160],\n",
      "         ...,\n",
      "         [0.6887, 0.2782, 0.7014],\n",
      "         [0.0312, 0.2256, 0.7841],\n",
      "         [0.6663, 0.2729, 0.0788]],\n",
      "\n",
      "        [[0.0094, 0.2294, 0.8958],\n",
      "         [0.6068, 0.0481, 0.1754],\n",
      "         [0.8739, 0.0670, 0.5417],\n",
      "         ...,\n",
      "         [0.9260, 0.1218, 0.0409],\n",
      "         [0.4629, 0.6014, 0.5497],\n",
      "         [0.4640, 0.9062, 0.2158]],\n",
      "\n",
      "        [[0.1015, 0.7591, 0.5533],\n",
      "         [0.5087, 0.2310, 0.3943],\n",
      "         [0.2888, 0.6591, 0.5034],\n",
      "         ...,\n",
      "         [0.4767, 0.4782, 0.6223],\n",
      "         [0.5369, 0.0837, 0.7304],\n",
      "         [0.9434, 0.2738, 0.4600]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7764, 0.0730, 0.5117],\n",
      "         [0.6333, 0.1247, 0.1301],\n",
      "         [0.0756, 0.4859, 0.1139],\n",
      "         ...,\n",
      "         [0.6483, 0.6456, 0.5700],\n",
      "         [0.3967, 0.2845, 0.2142],\n",
      "         [0.2725, 0.0059, 0.2231]],\n",
      "\n",
      "        [[0.7231, 0.7381, 0.4745],\n",
      "         [0.4478, 0.9465, 0.1431],\n",
      "         [0.5340, 0.9548, 0.3492],\n",
      "         ...,\n",
      "         [0.7633, 0.2947, 0.5862],\n",
      "         [0.6566, 0.1857, 0.6233],\n",
      "         [0.0658, 0.2672, 0.7307]],\n",
      "\n",
      "        [[0.0716, 0.7147, 0.9630],\n",
      "         [0.5173, 0.4201, 0.6413],\n",
      "         [0.4335, 0.7080, 0.5975],\n",
      "         ...,\n",
      "         [0.0126, 0.9572, 0.5768],\n",
      "         [0.7936, 0.4449, 0.3412],\n",
      "         [0.6404, 0.9607, 0.7217]]]) \n",
      "with a shape of: torch.Size([224, 224, 3]) and a dimension of: 3\n"
     ]
    }
   ],
   "source": [
    "random_image_tensor = torch.rand(224,224,3)\n",
    "print(f\"The Random Image Tensor is: {random_image_tensor} \\nwith a shape of: {random_image_tensor.shape} and a dimension of: {random_image_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d6ab1",
   "metadata": {},
   "source": [
    "## Zeros & Ones Tensors\n",
    "Sometimes, we just want to fill tensors with 0s or 1s specifically\n",
    "\n",
    "We do this alot with masking, which is when we 0 values so the model knows not to learn them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.float32\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.float32\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Creating a tensor full of 0s\n",
    "zeroes = torch.zeros(size=(3,4)) #size is optional, we can just use 3,4\n",
    "print(zeroes, zeroes.dtype)\n",
    "zero = torch.zeros(3,4)\n",
    "print(zero, zeroes.dtype)\n",
    "\n",
    "#Can do the same for creatin tensors of all ones\n",
    "ones = torch.ones(3,4)\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8917ed",
   "metadata": {},
   "source": [
    "### arange() Tensors\n",
    "- If we want a range of numbers such as 1-10 or 0-100, we can use torch.arrange(start, end, step)\n",
    "- Start: starty of range like 0\n",
    "- End: end of range like 10 IT WILL NOT INCLUDE THIS NUMBER\n",
    "    - If we want to include the end number, we can use torch.arange(start, end+1, step)\n",
    "- Step: Number of steps between each value like 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ffefe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20])\n"
     ]
    }
   ],
   "source": [
    "#goes from 0 to 9, dont need to write start=0, end=10, step=1\n",
    "zero_to_ten = torch.arange(start=0, end=11, step=1) \n",
    "print(zero_to_ten)\n",
    "\n",
    "#if we don't specify start, it will start at 0\n",
    "other = torch.arange(11) \n",
    "print(other)\n",
    "\n",
    "#if we want to get even numbers through 20\n",
    "evens_thru_20 = torch.arange(0,21,2)\n",
    "print(evens_thru_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4daa0",
   "metadata": {},
   "source": [
    "### Broadcasting like() Tensors\n",
    "- Sometimes you might want 1 tensor of a certain type with the same shape as another tensor\n",
    "- For example, a tensor with all 0s with the same shape as a previous tensor\n",
    "- You can use another tensor as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56c72ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21]) torch.Size([21])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "#Initialize tensor 1 to 21 (ndim=1, shape=(21,))\n",
    "one_to_21 = torch.arange(1,22)\n",
    "print(one_to_21, one_to_21.shape)\n",
    "\n",
    "#Create a tensor of all zeroes with the same shape as one_to_21\n",
    "twenty_one_zeroes = torch.zeros_like(one_to_21) #You could also write input=one_to_21 in the ()'s to be more specific\n",
    "print(twenty_one_zeroes, twenty_one_zeroes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe883fbb",
   "metadata": {},
   "source": [
    "## DIfferent Tensor Types\n",
    "- There are many different tensor datatypes in pyTorch, some specific for CPU and others for GPU\n",
    "    - Generally, if you see torch.cuda anywhere, the tensor is being used for GPU, since Nvidia GPUs use a computing toolkit called CUDA\n",
    "- The most common data type and generally the default is torch.float32 or torch.float, which is referred to as \"32-bit floating point\"\n",
    "    - There is also a 16-bit floating point: torch.float16 or torch.half\n",
    "    - A 64-bit floating point is torch.float64 or torch.double\n",
    "    - To confuse things even more, there are also 8, 16, 32, and 64 bit INTEGERS!\n",
    "    - The reason for all of these is for precision in computing, the amount of detail used to describe a number\n",
    "    - The higher the precision value (bits), the more detail and hence data used to express a number\n",
    "    - This all matters in DL because you're making so many operations, the more detail you have to calculate on, the more compute you have to use\n",
    "    - Lower precision data types are faster but sacrifice some performance on evaluation metrics like accuracy\n",
    "\n",
    "### 32 & 16-bit Floating Point Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b612e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The float 32 tensor is: tensor([3., 6., 9.]) with a shape of: torch.Size([3]) a datatype of:torch.float32 and is on the device: cpu\n",
      "The float 16 tensor is: tensor([1.0996, 2.1992, 3.3008], dtype=torch.float16) with a shape of: torch.Size([3]) a datatype of: torch.float16 and is on the device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Tensor Datatypes\n",
    "\n",
    "#We will implement the dtype parameter now\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                dtype=None, #will default to None anyway, which is torch.float32 \n",
    "                device=None, #will default to None, which is CPU\n",
    "                requires_grad=False) #if True, operations performed on the tensor are recorded for grad descent\n",
    "\n",
    "print(f\"The float 32 tensor is: {float_32_tensor} with a shape of: {float_32_tensor.shape} a datatype of:{float_32_tensor.dtype} and is on the device: {float_32_tensor.device}\")\n",
    "\n",
    "#Common issues\n",
    "#1. one of tensors is 16 bit and others is 32, PyTorch often likes its tensors in the same format\n",
    "#2. One of ur tensors is on the GPU and others is on the CPU, PyTorch likes the calculations to be on the same device\n",
    "\n",
    "#For now let us also create a float 16 tensor\n",
    "float_16_tensor = torch.tensor([1.1, 2.2, 3.3], #the numbers that will print will be different than 1.1, 2.2, 3.3 because of the precision for half's\n",
    "                            dtype=torch.half,\n",
    "                            device=None,\n",
    "                            requires_grad=False)\n",
    "\n",
    "print(f\"The float 16 tensor is: {float_16_tensor} with a shape of: {float_16_tensor.shape} a datatype of: {float_16_tensor.dtype} and is on the device: {float_16_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd4a64",
   "metadata": {},
   "source": [
    "# Getting Info from Tensors\n",
    "- Most commonly, we want to get shape, dtype, and device\n",
    "- Let's create a random tensor of size (3,2,2,1) and get these attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee43445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random tensor is: tensor([[[[0.9209],\n",
      "          [0.6574]],\n",
      "\n",
      "         [[0.2257],\n",
      "          [0.4435]]],\n",
      "\n",
      "\n",
      "        [[[0.9077],\n",
      "          [0.8990]],\n",
      "\n",
      "         [[0.1465],\n",
      "          [0.4703]]],\n",
      "\n",
      "\n",
      "        [[[0.9526],\n",
      "          [0.2359]],\n",
      "\n",
      "         [[0.6053],\n",
      "          [0.6296]]]])\n",
      "The shape is torch.Size([3, 2, 2, 1]), the datatype is torch.float32, and the device is cpu\n"
     ]
    }
   ],
   "source": [
    "taka_tensor = torch.rand(3,2,2,1) #think of a 3 sets of (pairs of (2x1 matrices)), which has ndim of 4\n",
    "print(f\"The random tensor is: {taka_tensor}\")\n",
    "print(f\"The shape is {taka_tensor.shape}, the datatype is {taka_tensor.dtype}, and the device is {taka_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876340ea",
   "metadata": {},
   "source": [
    "# Manipulating Tensors\n",
    "- In DL, data (images, text, video, audio, protein structures) gets represented as tensors\n",
    "- Model learns by investigating tensors, operations, and getting representation of patterns in the input data\n",
    "## Basic Operations\n",
    "- We will start with addition subtraction & multiplication\n",
    "- We will use +=, *=, etc. so that we re-assign the tensor\n",
    "- **Note**: If we just use * or =, the original tensor will stay the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92601bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:The original tensor was [1,2,3] and the new tensor is: tensor([11, 12, 13])\n",
      "Multiplication: The original tensor was [2,4,6,8] and the new tensor is: tensor([20, 40, 60, 80])\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor of values & do an operation\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "tensor += 10\n",
    "print(f\"Addition:The original tensor was [1,2,3] and the new tensor is: {tensor}\")\n",
    "\n",
    "mult_tensor = torch.tensor([2,4,6,8])\n",
    "mult_tensor *= 10\n",
    "print(f\"Multiplication: The original tensor was [2,4,6,8] and the new tensor is: {mult_tensor}\")\n",
    "\n",
    "#Can obviously do the same with subtraction and division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e29f47",
   "metadata": {},
   "source": [
    "### Built in Tensor Operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2622290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is: tensor([1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3,4,5])\n",
    "print(f\"The original tensor is: {tensor}\")\n",
    "torch.mul(tensor, 10) #Can use mul or multiply, same function\n",
    "#The above function did NOT change the actual tensor, we need to re-assign it to do that as previously\n",
    "\n",
    "#Another way to do this is to just use the * operator\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b73ae0",
   "metadata": {},
   "source": [
    "## Matrix Multiplication *torch.matmul()* or **@**\n",
    "- 1 of the most common operations in ML DL \n",
    "- the matmul() operator can be shortened to @\n",
    "    - Using @ on 1D tensors just computes the dot product, which returns a scalar (0D Tensor)\n",
    "    - Using @ on 2D Tensors requires the rules below\n",
    "- Rules\n",
    "    1. Inner dimensions must match: (3,2)@(2,3)\n",
    "    2. Resulting matrix has shape of outer dimensions, above gives a (3,3)\n",
    "\n",
    "### Example below: We work with 1D tensors (vectors), so @ yields dot product! This won't apply with ndim>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first tensor is: tensor([1, 2, 3]) \n",
      " and the second tensor is: tensor([4, 5, 6])\n",
      "Matrix Multiplication: 32\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1,2,3])\n",
    "tensor2 = torch.tensor([4,5,6])\n",
    "print(f\"The first tensor is: {tensor1} \\n and the second tensor is: {tensor2}\")\n",
    "\n",
    "matrix_multiplication = tensor1 @ tensor2\n",
    "print(f\"Matrix Multiplication: {matrix_multiplication}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831243df",
   "metadata": {},
   "source": [
    "### Matrix Mul by Hand via For loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c45ba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is: tensor([1, 2, 3]) with shape torch.Size([3]). The len(tensor) length function returns 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3]) \n",
    "value=0\n",
    "print(f\"The original tensor is: {tensor} with shape {tensor.shape}. The len(tensor) length function returns {len(tensor)}\")\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90449d16",
   "metadata": {},
   "source": [
    "# Shape Errors\n",
    "- One of the most common errors resulting from matrix multiplication\n",
    "## Using Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e8035b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A with shape torch.Size([3, 2]) and Tensor B with shape torch.Size([3, 2])\n",
      "Tensor A transpose is tensor([[1, 3, 5],\n",
      "        [2, 4, 6]]) and has shape torch.Size([2, 3])\n",
      "Multiplication of A^T @ B is tensor([[ 89,  98],\n",
      "        [116, 128]])\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1,2], #ndim=2, shape=torch.size([3,2])\n",
    "                        [3,4],\n",
    "                        [5,6]]\n",
    "                        )\n",
    "tensor_B = torch.tensor([[7,8],\n",
    "                        [9,10],\n",
    "                        [11,12]])\n",
    "#tensor_A @ tensor_B will throw an error because the inner dimensions do not match; cannot do a 3x2 @ 3x2\n",
    "\n",
    "#2 ways to transpose\n",
    "method1 = torch.transpose(tensor_A, 0,1) #input, and dimensions we will swap\n",
    "method2 = tensor_A.T #T is short for transpose\n",
    "\n",
    "print(f\"Tensor A with shape {tensor_A.shape} and Tensor B with shape {tensor_B.shape}\")\n",
    "print(f\"Tensor A transpose is {method2} and has shape {method2.shape}\")\n",
    "print(f\"Multiplication of A^T @ B is {method2 @ tensor_B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d19c5b",
   "metadata": {},
   "source": [
    "## Linear Modules\n",
    "- The *torch.nn.linear* module is known as the **feed-forward layer / fully connected layer**, implemented by the equation $$y=x*A^T+b$$\n",
    "- It implements a matrix multiplication between input *x* and weight matrix *W*\n",
    "    - $x$ is the input to the layer (DL is a stack of layers like torch.nn.Linear() and other on top of each other)\n",
    "    - $W$ is weights matrix created by the layer, randomly initialized, and we ALWAYS transpose it for matmul @\n",
    "    - $b$ is the bias term used to slightly offset the weights and inputs\n",
    "    - $y$ is the output, a manipulation of the input in hopes of discovering patterns in it\n",
    "- The torch.nn.Linear module is a linear function and can be used to draw a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88981a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor: tensor([[1., 3., 5.],\n",
      "        [2., 4., 6.]]) with a shape of: torch.Size([2, 3])\n",
      "Output Tensor: tensor([[0.9332, 0.8805, 3.0149, 1.5545, 1.8186, 2.0634],\n",
      "        [1.7186, 1.4009, 3.5818, 1.7408, 2.6017, 2.5123]],\n",
      "       grad_fn=<AddmmBackward0>) with a shape of: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "#Since the linear layer starts with a random weights matrix, let's make it reproducible\n",
    "torch.manual_seed(42) #this way we have consistency every time we initialize the random weights\n",
    "\n",
    "tensorA = torch.tensor([[1,2], #ndim=2, shape=torch.size([3,2])\n",
    "                        [3,4],\n",
    "                        [5,6]]\n",
    "                        )\n",
    "\n",
    "#We now use matmul\n",
    "linear = torch.nn.Linear(in_features=3, #matches inner dimension of input\n",
    "                        out_features=6) #decribes outer value\n",
    "\n",
    "x=tensorA.float().T #Our input tensor from earlier is a 3x2 matrix, and also we must make it into a float for torch.nn.Linear()\n",
    "output = linear(x) #Our output outer value will have 6 as its outer dimension, so we must make the inner dimension match with 2, so W is a 2x6\n",
    "print(f\"Input Tensor: {x} with a shape of: {x.shape}\")\n",
    "print(f\"Output Tensor: {output} with a shape of: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afbb5f2",
   "metadata": {},
   "source": [
    "## Aggregation: min, max, mean, sum \n",
    "Now that we have manipulated tensors, lets aggregate (going from more values to less values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76d0eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor is: tensor([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100])\n",
      "Min: 0, Max: 100, Mean: 50.0, Sum: 550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(100), tensor(0), tensor(50.), tensor(550))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,101,10)\n",
    "print(f\"The original tensor is: {x}\")\n",
    "\n",
    "print(f\"Min: {x.min()}, Max: {x.max()}, Mean: {x.type(torch.float32).mean()}, Sum: {x.sum()}\") \n",
    "#Mean MUST be a float, so we must convert x to a float for that argument\n",
    "\n",
    "#Alternative commands, but this will give you tensor outputs rather than normal floats/ints\n",
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358904cd",
   "metadata": {},
   "source": [
    "### Positional Min/Max\n",
    "- You can also find the index of a tensor where the max or min occurs with *torch.argmax()* and *torch.argmin()* respectively\n",
    "    - Remember, arg means argument here\n",
    "- This is helpful when we just want the position where the highest or lowest val is and not the actual value itself\n",
    "    - This will be used later when using the **softmax** activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5063b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423, 0.6343, 0.3644, 0.7104,\n",
      "        0.9464])\n",
      "The position of the min occuring value is 0 and the max is at 9\n"
     ]
    }
   ],
   "source": [
    "pos = torch.rand(10) #Remember with torch.rand, we aren't initializing the values, we are just creating a random tensor and each argument represents a dimension\n",
    "print(pos) #this example has a value of 10 in the 1st dimension, so we get a ndim=1 tensor (vector) with 10 nums\n",
    "\n",
    "print(f\"The position of the min occuring value is {pos.argmin()} and the max is at {pos.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025c205",
   "metadata": {},
   "source": [
    "## Datatypes and Tensor Precision\n",
    "- Different datatypes can be confusing to begin with.\n",
    "- the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value\n",
    "    - with a lower amount of storage, this generally results in faster computation and a smaller overall model\n",
    "- Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts\n",
    "### Type Casting a Float-32 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20b6712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.1000, 20.2000, 30.3000, 40.4000, 50.5000, 60.6000, 70.7000, 80.8000,\n",
      "        90.9000]) torch.float32\n",
      "tensor([10.1016, 20.2031, 30.2969, 40.4062, 50.5000, 60.5938, 70.6875, 80.8125,\n",
      "        90.8750], dtype=torch.float16)\n",
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10.1, 100.1, 10.1) #Default is float32\n",
    "print(tensor, tensor.dtype)\n",
    "\n",
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16) #changing a dtype is called type casting\n",
    "print(tensor_float16)\n",
    "\n",
    "# Create a float16 tensor\n",
    "tensor_int8 = tensor.type(torch.int8) #This will change the dtype to integer 8\n",
    "print(tensor_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cf978",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeeze/Unsqueezing\n",
    "- Often want to reshape or change the dimensions of your tensors without actually changing the values inside them\n",
    "    - Much more complex version of transposing\n",
    "- ```torch.reshape(input, shape)``` Reshapes input to shape if compatible, can also use ```torch.Tensor.reshape()```\n",
    "- ```Tensor.view(shape)``` Returns a view of the original tensor in a different shape but shares the same data as the original tensor\n",
    "- ```torch.stack(tensors, dim=0)``` Concatenates a sequence of tensors along a new dimensions (dim), all tensors must be the same size\n",
    "- ```torch.squeeze(input)``` Squeezes input to remove all the dimensions with value 1\n",
    "- ```torch.unsqueeze(input, dim)``` Returns input with a dimension value of 1 added at dim\n",
    "- ```torch.permute(input, dims)``` Returns a view of the original input with its dimensions permuted (rearranged) to dims\n",
    "\n",
    "We do these things because NNs are all about manipulating tensors in some way. These methods ensure we avoid matmul errors, and also mixing the right elements in the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fbc27e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our original tensor is tensor([1, 2, 3, 4, 5, 6, 7]) with shape torch.Size([7])\n",
      "\n",
      "Using .reshape we now have tensor([[1, 2, 3, 4, 5, 6, 7]]) with shape torch.Size([1, 7])\n",
      "\n",
      "Using .view() we now have tensor([[1, 2, 3, 4, 5, 6, 7]]) with shape torch.Size([1, 7]) while x is still tensor([1, 2, 3, 4, 5, 6, 7]) with shape torch.Size([7])\n",
      "\n",
      "Changing the view of z by replacing 0th element with 5: tensor([[5, 2, 3, 4, 5, 6, 7]]) changes the original tensor x: tensor([5, 2, 3, 4, 5, 6, 7])\n",
      "\n",
      "Using torch.stack([x,x,x,x], dim=0) (rows, 1st dimension) we now have tensor([[5, 2, 3, 4, 5, 6, 7],\n",
      "        [5, 2, 3, 4, 5, 6, 7],\n",
      "        [5, 2, 3, 4, 5, 6, 7],\n",
      "        [5, 2, 3, 4, 5, 6, 7]]) with shape torch.Size([4, 7])\n",
      "Using torch.stack() with dim=1 (columns, 2nd dimension) we now have tensor([[5, 5, 5, 5],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4],\n",
      "        [5, 5, 5, 5],\n",
      "        [6, 6, 6, 6],\n",
      "        [7, 7, 7, 7]]) with shape torch.Size([7, 4])\n",
      "\n",
      "Previous tensor before squeezing is: tensor([[5, 2, 3, 4, 5, 6, 7]]) with shape torch.Size([1, 7])\n",
      "The new tensor after squeezing (removing a extra dimension of 1) is: tensor([5, 2, 3, 4, 5, 6, 7]) with shape torch.Size([7])\n",
      "The new tensor after unsqueezing (adding a extra dimension of 1) is: tensor([[5, 2, 3, 4, 5, 6, 7]]) with shape torch.Size([1, 7])\n",
      "\n",
      "The original tensor is: tensor([[[0.7164, 0.2706, 0.6560],\n",
      "         [0.6614, 0.3648, 0.1490],\n",
      "         [0.8693, 0.0294, 0.5449],\n",
      "         ...,\n",
      "         [0.9462, 0.4235, 0.5523],\n",
      "         [0.6572, 0.0142, 0.4286],\n",
      "         [0.5314, 0.7014, 0.3068]],\n",
      "\n",
      "        [[0.7550, 0.6155, 0.6846],\n",
      "         [0.3695, 0.3440, 0.7202],\n",
      "         [0.2682, 0.1106, 0.6911],\n",
      "         ...,\n",
      "         [0.5185, 0.6390, 0.8082],\n",
      "         [0.0987, 0.7173, 0.5397],\n",
      "         [0.4045, 0.2029, 0.2845]],\n",
      "\n",
      "        [[0.4804, 0.6700, 0.9082],\n",
      "         [0.9641, 0.1178, 0.2395],\n",
      "         [0.7397, 0.2254, 0.5700],\n",
      "         ...,\n",
      "         [0.1519, 0.8649, 0.5733],\n",
      "         [0.5895, 0.4928, 0.2287],\n",
      "         [0.6585, 0.1298, 0.3462]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5735, 0.1949, 0.5349],\n",
      "         [0.5618, 0.5376, 0.5452],\n",
      "         [0.0983, 0.6775, 0.8993],\n",
      "         ...,\n",
      "         [0.0876, 0.0456, 0.1860],\n",
      "         [0.8916, 0.0225, 0.1665],\n",
      "         [0.9601, 0.0972, 0.4044]],\n",
      "\n",
      "        [[0.4718, 0.5772, 0.7063],\n",
      "         [0.0263, 0.9301, 0.0844],\n",
      "         [0.0296, 0.9484, 0.3487],\n",
      "         ...,\n",
      "         [0.2513, 0.5276, 0.2566],\n",
      "         [0.7141, 0.1638, 0.1576],\n",
      "         [0.2019, 0.0451, 0.7068]],\n",
      "\n",
      "        [[0.7605, 0.4634, 0.3114],\n",
      "         [0.2424, 0.5576, 0.8785],\n",
      "         [0.3823, 0.8733, 0.6629],\n",
      "         ...,\n",
      "         [0.3975, 0.4007, 0.9157],\n",
      "         [0.0821, 0.8882, 0.4257],\n",
      "         [0.2228, 0.6401, 0.8823]]]) with shape torch.Size([224, 224, 3])\n",
      "The permuted tensor is: tensor([[[0.7164, 0.6614, 0.8693,  ..., 0.9462, 0.6572, 0.5314],\n",
      "         [0.7550, 0.3695, 0.2682,  ..., 0.5185, 0.0987, 0.4045],\n",
      "         [0.4804, 0.9641, 0.7397,  ..., 0.1519, 0.5895, 0.6585],\n",
      "         ...,\n",
      "         [0.5735, 0.5618, 0.0983,  ..., 0.0876, 0.8916, 0.9601],\n",
      "         [0.4718, 0.0263, 0.0296,  ..., 0.2513, 0.7141, 0.2019],\n",
      "         [0.7605, 0.2424, 0.3823,  ..., 0.3975, 0.0821, 0.2228]],\n",
      "\n",
      "        [[0.2706, 0.3648, 0.0294,  ..., 0.4235, 0.0142, 0.7014],\n",
      "         [0.6155, 0.3440, 0.1106,  ..., 0.6390, 0.7173, 0.2029],\n",
      "         [0.6700, 0.1178, 0.2254,  ..., 0.8649, 0.4928, 0.1298],\n",
      "         ...,\n",
      "         [0.1949, 0.5376, 0.6775,  ..., 0.0456, 0.0225, 0.0972],\n",
      "         [0.5772, 0.9301, 0.9484,  ..., 0.5276, 0.1638, 0.0451],\n",
      "         [0.4634, 0.5576, 0.8733,  ..., 0.4007, 0.8882, 0.6401]],\n",
      "\n",
      "        [[0.6560, 0.1490, 0.5449,  ..., 0.5523, 0.4286, 0.3068],\n",
      "         [0.6846, 0.7202, 0.6911,  ..., 0.8082, 0.5397, 0.2845],\n",
      "         [0.9082, 0.2395, 0.5700,  ..., 0.5733, 0.2287, 0.3462],\n",
      "         ...,\n",
      "         [0.5349, 0.5452, 0.8993,  ..., 0.1860, 0.1665, 0.4044],\n",
      "         [0.7063, 0.0844, 0.3487,  ..., 0.2566, 0.1576, 0.7068],\n",
      "         [0.3114, 0.8785, 0.6629,  ..., 0.9157, 0.4257, 0.8823]]]) with shape torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,8)\n",
    "print(f\"Our original tensor is {x} with shape {x.shape}\")\n",
    "\n",
    "#Adding an extra dimension with torch.reshape()\n",
    "x_reshaped = x.reshape(1,7) #Here the (1,7) is the desired shape\n",
    "print(f\"\\nUsing .reshape we now have {x_reshaped} with shape {x_reshaped.shape}\")\n",
    "# Notice we keep the same number of elements so this is basically adding an extra dimension, exressing the vector as a row vector\n",
    "\n",
    "\n",
    "\n",
    "#We can also change the view with torch.view()\n",
    "#Again, this keeps data the same as original but changes the view, so it's basically the same as reshape\n",
    "z = x.view(1,7) \n",
    "print(f\"\\nUsing .view() we now have {z} with shape {z.shape} while x is still {x} with shape {x.shape}\")\n",
    "#Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor\n",
    "#So changing the view changes the original tensor too\n",
    "\n",
    "z[:, 0] = 5 #This will change the first element of the tensor\n",
    "print(f\"\\nChanging the view of z by replacing 0th element with 5: {z} changes the original tensor x: {x}\")\n",
    "\n",
    "\n",
    "\n",
    "#If we want to STACK our new tensor on top of itself 5 times, we could do that with torch.stack()\n",
    "#The dimension argument in stack is the dimension we want to stack along\n",
    "#So if we want to stack along first dimension, we use 0 (stack rows), whereas 2nd dimension, we use dim=1 and it stack columns\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0)\n",
    "print(f\"\\nUsing torch.stack([x,x,x,x], dim=0) (rows, 1st dimension) we now have {x_stacked} with shape {x_stacked.shape}\")\n",
    "x_stacked2 = torch.stack([x,x,x,x], dim=1)\n",
    "print(f\"Using torch.stack() with dim=1 (columns, 2nd dimension) we now have {x_stacked2} with shape {x_stacked2.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "#If we want to remove all single dimensions from a tensor, we can use torch.squeeze()\n",
    "#REMEMBER: Think of this as squeezing the tensor to only have dimensions over 1\n",
    "print(f\"\\nPrevious tensor before squeezing is: {x_reshaped} with shape {x_reshaped.shape}\")\n",
    "#Removing the extra dimension \n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"The new tensor after squeezing (removing a extra dimension of 1) is: {x_squeezed} with shape {x_squeezed.shape}\")\n",
    "\n",
    "#To reverse the removal of the 1-dimension, we can add a dimensions value of 1 at a specific index\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"The new tensor after unsqueezing (adding a extra dimension of 1) is: {x_unsqueezed} with shape {x_unsqueezed.shape}\")\n",
    "\n",
    "\n",
    "#Finally, we can also rearrange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims\n",
    "x_original = torch.rand(224,224,3) #remember with the rand initialization, the 0th dimension is the outermost (number of sets of 224x3 matrices)\n",
    "#Now we will permute to rearrange axes order\n",
    "x_permuted = x_original.permute(2,0,1) #JUST LOOK AT ORIGINAL TENSOR AND REARRANGE BASED ON THE NUMBER (2nd of OG, 0th of OG, 1st of OG), where OG was (0,1,2)\n",
    "print(f\"\\nThe original tensor is: {x_original} with shape {x_original.shape}\")\n",
    "print(f\"The permuted tensor is: {x_permuted} with shape {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565e26e",
   "metadata": {},
   "source": [
    "# Indexing (selecting data from tensors)\n",
    "- Sometimes, you'll want to select specific data from tensor (for example, only the first column or second row)\n",
    "- This is very similar to indexing on Python lists and NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e8986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
      "\n",
      "First square bracket y[0]: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket y[0][0]: tensor([1, 2, 3])\n",
      "Third square bracket y[0][0][0]: 1\n",
      "\n",
      "All Values of 0th dim, but only only 0 index of 1st dim y[:,0]: tensor([[1, 2, 3]])\n",
      "\n",
      "All values of 0th and 1st dim, but only index 1 of 2nd dim y[:,:,1]: tensor([[2, 5, 8]])\n",
      "\n",
      "All values of the 0th dimension but the 1 index values of the 1st & 2nd dims y[:,1,1]: tensor([5])\n",
      "\n",
      "Get index 0 of the 0th & 1st dim and all values of 2nd dimensions y[0,0,:]: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10) #gives me a 1D tensor (vector 1 thru 9), so 9 elements\n",
    "print(x)\n",
    "y = x.reshape(1,3,3) #This will work because 3x3 matrix contains 9 elements abd \n",
    "print(y, y.shape) \n",
    "\n",
    "#Indexing Values goes from OUTER TO INNER dimension (check out the square brackets)\n",
    "print(f\"\\nFirst square bracket y[0]: {y[0]}\") #This will return the full 3x3 matrix but squeezed; it is the first element of the ENTIRE tensor\n",
    "print(f\"Second square bracket y[0][0]: {y[0][0]}\") #This will give the first element of above, so the first row of the matrix (row vector)\n",
    "print(f\"Third square bracket y[0][0][0]: {y[0][0][0]}\") #This will give the first element of the row vector\n",
    "\n",
    "\n",
    "#You can also use : to specify \"all vals in this dimension\" and the use a comma to add another dimension\n",
    "print(f\"\\nAll Values of 0th dim, but only only 0 index of 1st dim y[:,0]: {y[:,0]}\") #Gets all values of 0th dimension (so keeps the outermost dimension) and only the 0th element of the 1st dimension\n",
    "\n",
    "#Get all values of the 0th & 1st dimensions, but only index 1 of 2nd dimension\n",
    "print(f\"\\nAll values of 0th and 1st dim, but only index 1 of 2nd dim y[:,:,1]: {y[:,:,1]}\")\n",
    "\n",
    "print(f\"\\nAll values of the 0th dimension but the 1 index values of the 1st & 2nd dims y[:,1,1]: {y[:,1,1]}\")\n",
    "#\n",
    "print(f\"\\nGet index 0 of the 0th & 1st dim and all values of 2nd dimensions y[0,0,:]: {y[0,0,:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3ff02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
